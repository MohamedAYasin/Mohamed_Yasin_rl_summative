# **Reinforcement Learning for Personalized Education**  

This project uses **Reinforcement Learning (RL)** to create an AI-powered **Personalized Learning System** that adapts dynamically to students' progress. The agent learns to **assess student understanding**, **provide tailored challenges**, and **adjust learning materials** to optimize learning outcomes.  

 <img src="https://github.com/user-attachments/assets/81a4e848-515c-4443-96ed-a0f52aca585a" width="800">

## **ğŸŒŸ Features**  
- **Custom Gym Environment** for RL-based education tracking  
- **Personalized Learning & Skill Development** using adaptive RL algorithms  
- **PyOpenGL + Pygame Rendering** for interactive visualization  
- **Multi-Step Decision Making** (Assess, Guide, Challenge, Adapt)  

## **ğŸ”— Links to Explore**

Document: 
Simulation Video:

## **ğŸ§  Reinforcement Learning in Education**  

### **ğŸ“Œ State Space (Minimum 4 States)**  
The RL model tracks student progress through four states:  

1ï¸âƒ£ **Struggling Learner** â€“ Needs extra support and guidance.  
2ï¸âƒ£ **Steady Learner** â€“ Making gradual progress but requires assistance.  
3ï¸âƒ£ **Independent Learner** â€“ Can solve problems with minimal help.  
4ï¸âƒ£ **Adaptive Learner** â€“ Highly competent, applying skills across challenges.  

### **ğŸ® Action Space (Minimum 4 Actions)**  
The AI tutor selects actions to guide the studentâ€™s learning:  

ğŸ”¹ **Action 1:** Simplify Content â€“ Adjusts material difficulty.  
ğŸ”¹ **Action 2:** Provide a Challenge â€“ Increases complexity for skill growth.  
ğŸ”¹ **Action 3:** Offer Immediate Feedback â€“ Gives hints or corrections.  
ğŸ”¹ **Action 4:** Introduce Alternative Learning Path â€“ Uses different methods for better understanding.  

### **ğŸ† Reward Criteria**  
âœ… **Positive Rewards:** When a student successfully progresses or completes tasks.  
âŒ **Negative Rewards:** If a student struggles repeatedly without improvement or disengages.  

### **ğŸ”š Terminal Conditions**  
The learning session ends when:  
- **Mastery Achieved:** Student reaches the **Adaptive Learner** state.  
- **Completion:** Student finishes the learning cycle.  
- **Persistent Struggle:** Student stays stuck in **Struggling Learner** state too long.  
- **Disengagement:** Student stops participating.  



## **ğŸš€ Setup Instructions**  

### **1ï¸âƒ£ Clone the Repository**  
```bash
git clone https://github.com/MohamedAYasin/Mohamed_Yasin_rl_summative.git
cd Mohamed_Yasin_rl_summative
```

### **2ï¸âƒ£ Create and Activate a Virtual Environment**  
```bash
python -m venv venv  

# Activate the virtual environment
# On Windows:
venv\Scripts\activate  

# On macOS/Linux:
source venv/bin/activate
```

### **3ï¸âƒ£ Install Dependencies**  
```bash
pip install -r requirements.txt
```



## **ğŸ–¥ï¸ Running the RL Agent**  

Run the environment without training:  
```bash
python play.py  
```


## **ğŸ“ˆ Future Improvements**  
ğŸ”¹ Fine-tune RL hyperparameters for better adaptation.  
ğŸ”¹ Improve curriculum learning for gradual difficulty adjustments.  
ğŸ”¹ Implement additional RL algorithms (SAC, TRPO) for better performance.  
ğŸ”¹ Extend the action space with more personalized interventions.  
ğŸ”¹ Add real-world integration with educational platforms.  

---

Â©ğŸ‘¤ **[Mohamed Ahmed Yasin](https://github.com/mohamedAYasin/)**

---
